{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\urasa\\Desktop\\UCL\\FYP\\_venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\urasa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\urasa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\urasa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import DataCollatorWithPadding, AutoTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download(\"punkt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"..\\\\article_scraping\\\\gemini_labelled_football_articles.csv\"\n",
    "\n",
    "def fix_csv_quotes(file_path, output_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    fixed_lines = []\n",
    "    fixed_lines.append(lines[0].strip() + '\\n')\n",
    "\n",
    "    for line in lines[1:]:\n",
    "        columns = line.split('\",\"')\n",
    "        fixed_columns = []\n",
    "        for column in columns:\n",
    "            fixed_column = column.replace('\"', '')\n",
    "            fixed_columns.append(fixed_column)\n",
    "        \n",
    "        fixed_line = '\",\"'.join(fixed_columns).strip()\n",
    "        fixed_line = f'\"{fixed_line}\"'\n",
    "        \n",
    "        fixed_lines.append(fixed_line)\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for fixed_line in fixed_lines:\n",
    "            f.write(fixed_line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_csv_quotes(csv_path, \"validation_sentences.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fixed_gemini_labelled_articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(label\n",
       " 0     0.631675\n",
       " 1     0.368186\n",
       " ,0    0.000140\n",
       " Name: proportion, dtype: float64,\n",
       "         count        mean        std   min   25%    50%    75%    max\n",
       " label                                                                \n",
       " ,0        1.0   58.000000        NaN  58.0  58.0   58.0   58.0   58.0\n",
       " 0      4519.0   99.712768  61.842954   6.0  48.0   89.0  138.0  425.0\n",
       " 1      2634.0  127.555429  62.358228  17.0  79.0  118.0  166.0  440.0,\n",
       " article_topic\n",
       " PL hits and misses: Palmer makes history; Arsenal become title favourites    53\n",
       " Man Utd ate Crystal Palace alive in stalemate; says Ten Hag                  46\n",
       " Four-goal Palmer best in PL; says Maresca after Chelsea beat Brighton        37\n",
       " Hits and misses: Jackson repaying Maresca's faith                            36\n",
       " Hits and misses: Liverpool serious contenders as City show flaws             35\n",
       " Merson Says: Man City now fully aware of threat posed by Arsenal             35\n",
       " 'Stick to the plan' - Ten Hag interview in full ahead of crunch week         33\n",
       " Merson Says: Chelsea will hurt themselves with obsessive style               32\n",
       " Slot's perfect start is over - here's what went wrong...                     32\n",
       " Brighton win five-goal thriller as Spurs suffer second-half collapse         32\n",
       " Name: count, dtype: int64,\n",
       " article_topic\n",
       " On-song Fulham inflict first loss of season on Newcastle                       0.709677\n",
       " Man Utd ate Crystal Palace alive in stalemate; says Ten Hag                    0.707692\n",
       " Brighton win five-goal thriller as Spurs suffer second-half collapse           0.640000\n",
       " Ange: Brighton collapse worst defeat of my Spurs tenure                        0.620000\n",
       " Son criticises fixture demands: We're not robots                               0.596154\n",
       " Wolves maintain full O'Neil support as club part ways with set-piece coach     0.578947\n",
       " Merson on Ange's trophy claims: 'I’ve got more chance of winning Strictly!'    0.574074\n",
       " Man Utd hold Aston Villa to ease pressure on Ten Hag                           0.571429\n",
       " Man City; PL both claim victory in ruling over commercial deals                0.571429\n",
       " Everton blow another lead in draw at Leicester amid thunderstorm               0.571429\n",
       " Name: label, dtype: float64,\n",
       " league       331\n",
       " game         257\n",
       " season       239\n",
       " premier      235\n",
       " city         189\n",
       " team         188\n",
       " half         167\n",
       " players      163\n",
       " games        160\n",
       " arsenal      153\n",
       " united       141\n",
       " time         139\n",
       " said         137\n",
       " goal         130\n",
       " ball         128\n",
       " win          127\n",
       " like         122\n",
       " second       117\n",
       " going        115\n",
       " liverpool    114\n",
       " dtype: int64,\n",
       " league        535\n",
       " season        367\n",
       " premier       350\n",
       " city          291\n",
       " time          265\n",
       " game          257\n",
       " arsenal       239\n",
       " club          210\n",
       " players       209\n",
       " half          192\n",
       " team          187\n",
       " united        185\n",
       " games         182\n",
       " just          178\n",
       " said          165\n",
       " second        158\n",
       " manchester    152\n",
       " liverpool     148\n",
       " ball          144\n",
       " goal          144\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class distribution: Arguments vs Non-Arguments\n",
    "class_distribution = df['label'].value_counts(normalize=True)\n",
    "\n",
    "# Sentence length analysis\n",
    "df['sentence_length'] = df['sentence'].apply(len)\n",
    "sentence_length_stats = df.groupby('label')['sentence_length'].describe()\n",
    "\n",
    "# Top article topics by the number of arguments\n",
    "top_topics_by_arguments = df[df['label'] == '1']['article_topic'].value_counts().head(10)\n",
    "\n",
    "# Argument density per topic (ratio of arguments to non-arguments within each topic)\n",
    "argument_density = df.groupby('article_topic')['label'].apply(lambda x: (x == '1').mean()).sort_values(ascending=False).head(10)\n",
    "\n",
    "# Keyword analysis (frequent words in arguments vs non-arguments), Arguments\n",
    "vectorizer_args = CountVectorizer(stop_words='english', max_features=20)\n",
    "X_args = vectorizer_args.fit_transform(df[df['label'] == '1']['sentence'])\n",
    "keywords_args = pd.DataFrame(X_args.toarray(), columns=vectorizer_args.get_feature_names_out()).sum().sort_values(ascending=False)\n",
    "\n",
    "# Non-arguments\n",
    "vectorizer_non_args = CountVectorizer(stop_words='english', max_features=20)\n",
    "X_non_args = vectorizer_non_args.fit_transform(df[df['label'] == '0']['sentence'])\n",
    "keywords_non_args = pd.DataFrame(X_non_args.toarray(), columns=vectorizer_non_args.get_feature_names_out()).sum().sort_values(ascending=False)\n",
    "\n",
    "class_distribution, sentence_length_stats, top_topics_by_arguments, argument_density, keywords_args, keywords_non_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WHAT KIND OF FEATURES WOULD I LIKE TO INCLUDE FOR BETTER IDENTIFICATION\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=50)\n",
    "argument_df = df[df['label'] == '1']\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(argument_df['sentence'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['best', 'better', 'big', 'did', 'going', 'good', 'just', 'know', 'like',\n",
       "       'lot', 'make', 'need', 'new', 'play', 'really', 'right', 'said',\n",
       "       'start', 'think', 've', 'want', 'way', 'win'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df.drop(columns=['arsenal', 'united', 'chelsea', 'city', 'club', 'don', 'football', 'game', 'games', 'goals', 'hag', 'half', 'league', 'liverpool', 'manchester', 'man', 'minutes', 'player', 'players', 'premier', 'season', 'second', 'team', 'time', 'ball', 'manager', 'goal', ], inplace=True)\n",
    "tfidf_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_keywords = tfidf_df.columns.tolist()  \n",
    "tfidf_all_sentences = tfidf_vectorizer.transform(df['sentence'])\n",
    "tfidf_all_df = pd.DataFrame(tfidf_all_sentences.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_all_filtered = tfidf_all_df[filtered_keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df.reset_index(drop=True), tfidf_all_filtered.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNouns and Proper Nouns:\\n\\nNN: Noun, singular (e.g., \"dog\")\\nNNS: Noun, plural (e.g., \"dogs\")\\nNNP: Proper noun, singular (e.g., \"John\")\\nNNPS: Proper noun, plural (e.g., \"Americans\")\\nVerbs:\\n\\nVB: Base form (e.g., \"run\")\\nVBD: Past tense (e.g., \"ran\")\\nVBG: Gerund or present participle (e.g., \"running\")\\nVBN: Past participle (e.g., \"driven\")\\nVBP: Present tense, not 3rd person singular (e.g., \"run\" in \"they run\")\\nVBZ: Present tense, 3rd person singular (e.g., \"runs\")\\nAdjectives and Comparatives:\\n\\nJJ: Adjective (e.g., \"big\")\\nJJR: Adjective, comparative (e.g., \"bigger\")\\nJJS: Adjective, superlative (e.g., \"biggest\")\\nAdverbs:\\n\\nRB: Adverb (e.g., \"quickly\")\\nRBR: Adverb, comparative (e.g., \"faster\")\\nRBS: Adverb, superlative (e.g., \"fastest\")\\nPronouns and Determiners:\\n\\nPRP: Personal pronoun (e.g., \"he\", \"they\")\\nPRP$: Possessive pronoun (e.g., \"his\", \"her\")\\nDT: Determiner (e.g., \"the\", \"a\")\\nWP: Wh-pronoun (e.g., \"who\", \"what\")\\nWP$: Possessive wh-pronoun (e.g., \"whose\")\\nWDT: Wh-determiner (e.g., \"which\")\\nPrepositions and Conjunctions:\\n\\nIN: Preposition or subordinating conjunction (e.g., \"in\", \"because\")\\nCC: Coordinating conjunction (e.g., \"and\", \"or\")\\nTO: \"to\" (as in \"to go\")\\nOthers:\\n\\nMD: Modal verb (e.g., \"can\", \"will\")\\nPOS: Possessive ending (e.g., \"\\'s\")\\nRP: Particle (e.g., \"up\" in \"give up\")\\nEX: Existential \"there\" (e.g., \"there is\")\\nFW: Foreign word (e.g., words from other languages)\\nUH: Interjection (e.g., \"uh\", \"well\")\\nSYM: Symbol (e.g., \"&\", \"%\")\\n$: Dollar sign\\nPunctuation:\\n\\n.: Sentence-ending punctuation (e.g., period, exclamation point)\\n,: Comma\\n:: Colon\\n( and ): Parentheses\\n\\n\\n'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Nouns and Proper Nouns:\n",
    "\n",
    "NN: Noun, singular (e.g., \"dog\")\n",
    "NNS: Noun, plural (e.g., \"dogs\")\n",
    "NNP: Proper noun, singular (e.g., \"John\")\n",
    "NNPS: Proper noun, plural (e.g., \"Americans\")\n",
    "Verbs:\n",
    "\n",
    "VB: Base form (e.g., \"run\")\n",
    "VBD: Past tense (e.g., \"ran\")\n",
    "VBG: Gerund or present participle (e.g., \"running\")\n",
    "VBN: Past participle (e.g., \"driven\")\n",
    "VBP: Present tense, not 3rd person singular (e.g., \"run\" in \"they run\")\n",
    "VBZ: Present tense, 3rd person singular (e.g., \"runs\")\n",
    "Adjectives and Comparatives:\n",
    "\n",
    "JJ: Adjective (e.g., \"big\")\n",
    "JJR: Adjective, comparative (e.g., \"bigger\")\n",
    "JJS: Adjective, superlative (e.g., \"biggest\")\n",
    "Adverbs:\n",
    "\n",
    "RB: Adverb (e.g., \"quickly\")\n",
    "RBR: Adverb, comparative (e.g., \"faster\")\n",
    "RBS: Adverb, superlative (e.g., \"fastest\")\n",
    "Pronouns and Determiners:\n",
    "\n",
    "PRP: Personal pronoun (e.g., \"he\", \"they\")\n",
    "PRP$: Possessive pronoun (e.g., \"his\", \"her\")\n",
    "DT: Determiner (e.g., \"the\", \"a\")\n",
    "WP: Wh-pronoun (e.g., \"who\", \"what\")\n",
    "WP$: Possessive wh-pronoun (e.g., \"whose\")\n",
    "WDT: Wh-determiner (e.g., \"which\")\n",
    "Prepositions and Conjunctions:\n",
    "\n",
    "IN: Preposition or subordinating conjunction (e.g., \"in\", \"because\")\n",
    "CC: Coordinating conjunction (e.g., \"and\", \"or\")\n",
    "TO: \"to\" (as in \"to go\")\n",
    "Others:\n",
    "\n",
    "MD: Modal verb (e.g., \"can\", \"will\")\n",
    "POS: Possessive ending (e.g., \"'s\")\n",
    "RP: Particle (e.g., \"up\" in \"give up\")\n",
    "EX: Existential \"there\" (e.g., \"there is\")\n",
    "FW: Foreign word (e.g., words from other languages)\n",
    "UH: Interjection (e.g., \"uh\", \"well\")\n",
    "SYM: Symbol (e.g., \"&\", \"%\")\n",
    "$: Dollar sign\n",
    "Punctuation:\n",
    "\n",
    ".: Sentence-ending punctuation (e.g., period, exclamation point)\n",
    ",: Comma\n",
    ":: Colon\n",
    "( and ): Parentheses\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_tags = {\n",
    "        'NOUN': {'NN', 'NNS', 'NNP', 'NNPS'},\n",
    "        'VERB': {'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'},\n",
    "        'ADJ': {'JJ', 'JJR', 'JJS'},\n",
    "        'ADV': {'RB', 'RBR', 'RBS'},\n",
    "        'PRON': {'PRP', 'PRP$', 'WP', 'WP$'},\n",
    "        'WDT': {'WDT'},\n",
    "        'PREP': {'IN', 'TO'},\n",
    "        'MODAL': {'MD'},\n",
    "        'NUM': {'CD'},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag_distribution(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tags = [tag for word, tag in pos_tag(tokens)]\n",
    "    grouped_counts = {group: 0 for group in grouped_tags.keys()}\n",
    "    \n",
    "    for tag in tags:\n",
    "        for group, members in grouped_tags.items():\n",
    "            if tag in members:\n",
    "                grouped_counts[group] += 1\n",
    "                break\n",
    "    \n",
    "        \n",
    "    tag_counts = pd.Series(grouped_counts).div(len(tags))\n",
    "    return tag_counts\n",
    "\n",
    "pos_tags_df = df['sentence'].apply(pos_tag_distribution).fillna(0)\n",
    "df = pd.concat([df.reset_index(drop=True), pos_tags_df.reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "topic_encoded = one_hot_encoder.fit_transform(df[['article_topic']]).toarray()\n",
    "topic_encoded_df = pd.DataFrame(topic_encoded, columns=one_hot_encoder.get_feature_names_out(['article_topic']))\n",
    "df = pd.concat([df, topic_encoded_df], axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of boolean values returned per article\n",
    "argument_density_per_topic = df.groupby('article_topic')['label'].apply(lambda x: (x == '1').mean())\n",
    "df['argument_density'] = df['article_topic'].map(argument_density_per_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Topic - Argument Density:\n",
      "On-song Fulham inflict first loss of season on Newcastle: 0.7096774193548387\n",
      "Man Utd ate Crystal Palace alive in stalemate; says Ten Hag: 0.7076923076923077\n",
      "Brighton win five-goal thriller as Spurs suffer second-half collapse: 0.64\n",
      "Neville: Arsenal the only team who can take on ominous Man City: 0.627906976744186\n",
      "Ange: Brighton collapse worst defeat of my Spurs tenure: 0.62\n",
      "Forest owner Marinakis banned for spitting near officials after Fulham loss: 0.6153846153846154\n",
      "Son criticises fixture demands: We're not robots: 0.5961538461538461\n",
      "Papers: Real Madrid 'regret' signing Mbappe: 0.5789473684210527\n",
      "Wolves maintain full O'Neil support as club part ways with set-piece coach: 0.5789473684210527\n",
      "Merson on Ange's trophy claims: 'I’ve got more chance of winning Strictly!': 0.5740740740740741\n",
      "Everton blow another lead in draw at Leicester amid thunderstorm: 0.5714285714285714\n",
      "Man City; PL both claim victory in ruling over commercial deals: 0.5714285714285714\n",
      "Man Utd hold Aston Villa to ease pressure on Ten Hag: 0.5714285714285714\n",
      "Defiant Ten Hag: We can turn this around and make season a success: 0.5681818181818182\n",
      "Ref Watch: Trossard red; Doku escape & Man City-Arsenal flashpoints explained: 0.56\n",
      "PL hits and misses: Palmer makes history; Arsenal become title favourites: 0.5578947368421052\n",
      "Neville: Liverpool 'well below' Arsenal and Man City: 0.5555555555555556\n",
      "Hits and misses: Three-horse title race hotting up already: 0.5535714285714286\n",
      "Carra: Newcastle must be careful not to lose Howe after poor window: 0.5526315789473685\n",
      "Arteta praises Arsenal for winning ugly as Gabriel downs Spurs: 0.5476190476190477\n",
      "Alisson injured but PL leaders Liverpool hang on to beat Palace: 0.5428571428571428\n",
      "Record-breaking Haaland at the double as Man City edge Brentford: 0.5428571428571428\n",
      "Slot's perfect start is over - here's what went wrong...: 0.5423728813559322\n",
      "Papers: Arsenal's Tomiyasu 'open' to January transfer exit: 0.5416666666666666\n",
      "Ref Watch: Were Stones; Saliba calls right? Did Chelsea deserve a penalty?: 0.5333333333333333\n",
      "How sensational Saka is still improving for Arsenal: 0.5319148936170213\n",
      "Four-goal Palmer best in PL; says Maresca after Chelsea beat Brighton: 0.5285714285714286\n",
      "Carra and Nev analyse title race: 'Man City have the edge': 0.5263157894736842\n",
      "Jones stars as Liverpool beat Chelsea in incident-packed game: 0.5227272727272727\n",
      "Merson Says: Chelsea will hurt themselves with obsessive style: 0.5161290322580645\n",
      "'That's the way to hurt them': Carra identifies Man City weak spot: 0.5142857142857142\n",
      "Bowen shines as Lopetegui secures first home PL win as West Ham boss: 0.5111111111111111\n",
      "Hudson-Odoi fires Forest to first win at Liverpool in 55 years: 0.5087719298245614\n",
      "'No civil war' as clubs plan PL show of support after Man City case: 0.5\n",
      "Explained: Why Man Utd are standing by Ten Hag: 0.5\n",
      "Jackson punishes woeful Hammers as Chelsea ease to victory: 0.5\n",
      "Papers: Everton could try to tempt Mourinho: 0.5\n",
      "Papers: Gomes refuses to rule out potential return to Man Utd: 0.5\n",
      "Papers: Man Utd must fork out £17.5m to sack Ten Hag: 0.5\n",
      "Player handed 10-match ban for racially abusing Wolves' Hwang: 0.5\n",
      "Ref Watch: Should Fernandes have seen red?: 0.5\n",
      "The alarming stats for Ten Hag and Man Utd: 0.5\n",
      "Solanke has lift-off at Spurs; Tielemans filling Luiz void for Villa: 0.4897959183673469\n",
      "Neville: Villa draw has given Ten Hag time; but next few weeks critical: 0.4838709677419355\n",
      "Fulham beat Forest as Jimenez penalty hands hosts first defeat of season: 0.475\n",
      "Ten Hag floundering but should Man Utd chiefs have seen it coming?: 0.47368421052631576\n",
      "Are Slot's Liverpool Premier League title contenders?: 0.47058823529411764\n",
      "Diaz at the double as Liverpool beat Bournemouth: 0.47058823529411764\n",
      "Papers: Man Utd chief tells staff that plan is to win PL in 2028: 0.47058823529411764\n",
      "Saliba to miss Liverpool clash - how big a miss will he be?: 0.46808510638297873\n",
      "Fernandes red card overturned after successful Man Utd appeal: 0.4666666666666667\n",
      "Man Utd sink to new low as Spurs impress: 0.4666666666666667\n",
      "Stones' stoppage-time winner sends Man City top at Wolves: 0.46551724137931033\n",
      "Hits and misses: Arsenal's biggest strength still a major Spurs weakness: 0.4642857142857143\n",
      "Anger inspired Man Utd comeback win over Brentford; says Ten Hag: 0.46153846153846156\n",
      "Papers: Rodri and TAA part of Real Madrid's ambitious transfer plan: 0.46153846153846156\n",
      "Q&A: Who is the winner from Man City vs PL case - and what now?: 0.46153846153846156\n",
      "Liverpool go top at Wolves but Slot warns: 'We have a lot to prove': 0.46\n",
      "Can Leicester; Ipswich and Southampton survive in the Premier League?: 0.4583333333333333\n",
      "Man Utd quieten the noise with routine win at Southampton: 0.4583333333333333\n",
      "Raya's stunning double save from penalty earns Arsenal point at Atalanta: 0.45714285714285713\n",
      "Ange responds to 'second season' criticism: It's true yet it upset people: 0.45454545454545453\n",
      "Ref Watch: Should Arsenal's Timber have been sent off at Spurs?: 0.45454545454545453\n",
      "Ten Hag hits back at critics for creating 'lies and fairytales': 0.4523809523809524\n",
      "Duran stars in another late Villa blitz to see off Wolves: 0.45161290322580644\n",
      "Dyche retains full backing of Everton hierarchy: 0.45\n",
      "Late Ings effort rescues point for West Ham against Fulham: 0.4473684210526316\n",
      "Arteta: 'Dark arts' claims are opinions; I prefer facts: 0.4444444444444444\n",
      "Former Liverpool defender Matip retires aged 33: 0.4375\n",
      "Papers: Premier League clubs interested in England midfielder Gomes: 0.4375\n",
      "Silva makes Arsenal trophy dig and appears to mock Gabriel: 0.4375\n",
      "Merson Says: Arsenal out of title race if they lose to Liverpool: 0.43636363636363634\n",
      "Late Ipswich equaliser denies Saints first win of season: 0.43478260869565216\n",
      "How Viana rose from unfulfilled talent to Man City director of football: 0.4342105263157895\n",
      "Arteta facing huge test as depleted Arsenal run fixture gauntlet: 0.4339622641509434\n",
      "'Stick to the plan' - Ten Hag interview in full ahead of crunch week: 0.42857142857142855\n",
      "Papers: Roma legend Totti teases Serie A return: 0.42857142857142855\n",
      "'I'm open to anything' - Potter on Man Utd; England; Chelsea and more: 0.423728813559322\n",
      "Hits and misses: Jackson repaying Maresca's faith: 0.4235294117647059\n",
      "'It's got to stop' - Neville slams Wolves' tactics in Liverpool defeat: 0.42105263157894735\n",
      "Webb: VAR has made just two errors this season - but is he right?: 0.4117647058823529\n",
      "Wood heaps more misery on Palace as Glasner admits to confidence dip: 0.4090909090909091\n",
      "Players' union and leagues file complaint over 'abusive' FIFA calendar: 0.40816326530612246\n",
      "Klopp speaks as he lines up return to football... but not as a coach!: 0.40789473684210525\n",
      "Rodri says players 'close' to striking due to increasing fixture demands: 0.40625\n",
      "PL hits and misses: Evans rolls back the years as Man Utd hold out: 0.40476190476190477\n",
      "Everton continue to back Dyche after Carabao Cup exit: 0.4\n",
      "Neville: Man Utd display 'absolutely disgusting': 0.4\n",
      "Nottingham Forest fined over social media comments about VAR Attwell: 0.4\n",
      "Odegaard out for 'a while' with 'quite significant' ligament damage: 0.4\n",
      "Premier League rejects Man City's accusation it 'misled' clubs over APT case: 0.4\n",
      "Son struggling as Spurs form tests faith in 'Angeball': 0.4\n",
      "Duran is Villa's hero as Everton throw away two-goal lead again: 0.3968253968253968\n",
      "Missed penalty; red card and an own goal - Fulham implode in Villa win: 0.3939393939393939\n",
      "Arteta furious with Trossard red as Stones calls out Arsenal 'dark arts': 0.39215686274509803\n",
      "What's a transition? A false nine? A low block? Football's Alternative Dictionary: 0.3893129770992366\n",
      "Hits and misses: Liverpool serious contenders as City show flaws: 0.3888888888888889\n",
      "Diaz transformed at Liverpool under Slot: 0.3877551020408163\n",
      "Duran signs new Aston Villa deal after blistering season start: 0.38461538461538464\n",
      "Papers: Palmer central to Carsley's England plans: 0.38461538461538464\n",
      "Merson Says: Man City now fully aware of threat posed by Arsenal: 0.3804347826086957\n",
      "Arteta explains Man City comments after Pep called for clarity: 0.37777777777777777\n",
      "PL Predictions: Can Liverpool take golden chance at Arsenal?: 0.373134328358209\n",
      "The brains behind Brentford's kick-off ploys: 0.3684210526315789\n",
      "Ten Hag 'happy' with Rashford after Redknapp questions Palace omission: 0.36666666666666664\n",
      "McKenna bemoans 'inexplicable' penalty call as Everton beat winless Ipswich: 0.36363636363636365\n",
      "Newcastle come from behind to beat Wolves and move third: 0.36363636363636365\n",
      "Why Villa went for Onana from Everton: 0.36\n",
      "Who could possibly replace Rodri at Man City?: 0.3582089552238806\n",
      "Diaz: We want to win it all under 'spectacular' Slot: 0.35714285714285715\n",
      "Gordon signs new long-term Newcastle deal: 0.35714285714285715\n",
      "What is going wrong for Lopetegui at West Ham?: 0.35714285714285715\n",
      "Ange on set-pieces: It's my burden to carry | 'Spurs are scared of them': 0.3561643835616438\n",
      "Arsenal can reawaken the Man City Sterling: 0.3541666666666667\n",
      "Jota or Nunez? Replacing Firmino at Liverpool explained: 0.35384615384615387\n",
      "'Not great news' - Calafiori injury adds to Arteta's woes ahead of Liverpool: 0.35294117647058826\n",
      "Kovacic at the double as Man City punish wasteful Fulham: 0.35\n",
      "Papers: Bayern target move for Liverpool goalkeeper Alisson: 0.35\n",
      "'Kudus punched me' | Van de Ven and Ange confused by Tottenham fine: 0.34782608695652173\n",
      "Assessing Everton's dire start: Can Dyche shake off annual sluggishness?: 0.3472222222222222\n",
      "Onana: Man Utd players taking responsibility for mistakes: 0.3448275862068966\n",
      "FA asks O'Neil for observations over comments about officials: 0.34210526315789475\n",
      "Papers: Man Utd set to be frustrated in pursuit of Bayern star Davies: 0.3333333333333333\n",
      "The stat that shows Ten Hag among best in PL: 0.3333333333333333\n",
      "Trent tweak and Konate impact key to Liverpool's formidable defence: 0.3333333333333333\n",
      "McKenna: Our Premier League style? We're still finding out... : 0.32786885245901637\n",
      "Hits and misses: Garnacho ignites Man Utd as Sarr changes game for Spurs: 0.32653061224489793\n",
      "Nkunku and Sancho combine to give Chelsea win at unlucky Bournemouth: 0.32608695652173914\n",
      "Seven games in 22 days: What Ten Hag needs from Man Utd's upcoming run: 0.32558139534883723\n",
      "Arsenal score twice late on to beat Leicester in 'emotional' win: 0.3230769230769231\n",
      "McNeil's double fires Everton to first PL victory over winless Palace: 0.3225806451612903\n",
      "Slot on risk vs reward; perfection and 'special' Alexander-Arnold: 0.31958762886597936\n",
      "PGMOL rejects Leicester boss Cooper's 'awful human error' VAR claim: 0.3181818181818182\n",
      "Ref told Rice 'I don't like the rule' as he sent him off vs Brighton : 0.3181818181818182\n",
      "Saka inspires Arsenal to comeback win over Saints: 0.3157894736842105\n",
      "Another Mbeumo first-minute strike not enough as West Ham hold Brentford: 0.3142857142857143\n",
      "Martin 'so hurt' by Southampton display as Bournemouth cruise to win: 0.3103448275862069\n",
      "Leicester hang on to beat Bournemouth after Buonanotte solo effort: 0.30952380952380953\n",
      "Injured Alisson set for a 'few weeks' out: 0.3076923076923077\n",
      "Man Utd stadium plans: What we know so far: 0.3076923076923077\n",
      "Papers: PL clubs agree plan to close transfer window before start of 2025/26 season: 0.3076923076923077\n",
      "Stones salvages draw for Man City against 10-player Arsenal: 0.3076923076923077\n",
      "Ten Hag: We know it's not a good start but owners are with me: 0.3076923076923077\n",
      "'Villa made me feel wanted' | Iling-Junior eyeing spot in Emery's plans: 0.3055555555555556\n",
      "Papers: Real Madrid to ignite move for Trent?: 0.30434782608695654\n",
      "How would Guardiola set up Man City without De Bruyne?: 0.30303030303030304\n",
      "Rampant Spurs hit three goals in eight minutes to seal big West Ham win: 0.30303030303030304\n",
      "Arsenal's red-card problem analysed - ill-discipline or bad luck?: 0.30158730158730157\n",
      "Five-phase plan; job title change; Edu bond - How Arteta changed Arsenal: 0.2962962962962963\n",
      "Man City confirm Rodri suffered knee ligament injury: 0.29411764705882354\n",
      "Nuno's fast breaks; Duran's strike; Nketiah's impact: 0.29411764705882354\n",
      "O'Neil: Do refs have 'subconscious' bias toward big clubs?: 0.29411764705882354\n",
      "Carra: Jones proved Liverpool don't need Zubimendi : 0.2926829268292683\n",
      "Papers: Man City could be hit with points deductions 'across multiple seasons': 0.2916666666666667\n",
      "Howe; Ancelotti not contacted by FA; Pep coy on England conversations: 0.2857142857142857\n",
      "Ugarte's tough task at Man Utd; deadly Hudson-Odoi a Forest bargain: 0.2857142857142857\n",
      "Villa miss chance to go second after Ipswich fightback: 0.2857142857142857\n",
      "Welbeck strike sends Brighton fifth as Newcastle left frustrated : 0.2857142857142857\n",
      "How Milenkovic helped transform Forest's defence: 0.2839506172839506\n",
      "Why 'rock and roll' Bournemouth 'should' be fourth: 0.2815533980582524\n",
      "Are players overworked? The truth revealed....: 0.28125\n",
      "Hits and misses: Hope for the rest - Man City are vulnerable!: 0.28125\n",
      "Papers: Arsenal weigh up move for Leverkusen star Wirtz: 0.28125\n",
      "Webb: Bournemouth disallowed goal vs Newcastle should have stood: 0.28125\n",
      "'Big errors; silly mistakes': Arsenal rue latest red in Bournemouth loss: 0.2807017543859649\n",
      "Arteta: Unbelievable Saka has taken another step up: 0.27586206896551724\n",
      "Kick It Out founder Lord Herman Ouseley dies aged 79: 0.2727272727272727\n",
      "How Spursy was collapse at Brighton? Tottenham's PL capitulations compared: 0.2702702702702703\n",
      "Wilshere leaves Arsenal to join Norwich as first-team coach: 0.2692307692307692\n",
      "'I think this is the year' – Saka backs Arsenal to dethrone Man City: 0.26666666666666666\n",
      "Papers: Man City eye move for ex-Liverpool target Zubimendi: 0.265625\n",
      "'Best PL centre-back ever' Van Dijk in talks over Liverpool future: 0.2631578947368421\n",
      "Rashford's creativity hints at return to form: 0.2619047619047619\n",
      "Incredible saves; one red card and 38 shots as Forest hold Chelsea: 0.25925925925925924\n",
      "Tonali: I was living two lives before betting ban: 0.25806451612903225\n",
      "O'Neil slams 'worst' Wolves performance after heavy Brentford defeat: 0.2564102564102564\n",
      "PL hits and misses: Arsenal show resilience as Haaland makes it a ton: 0.2564102564102564\n",
      "Papers: PL clubs complain to PGMOL over Arsenal's use of 'dark arts': 0.2564102564102564\n",
      "Carsley offers Arsenal injury boost after Saka leaves England camp: 0.25\n",
      "Gordon misses penalty as Everton hold Newcastle: 0.25\n",
      "Martin not fearing sack after Southampton collapse against Leicester: 0.25\n",
      "McNeil's new role; Kulusevski's creativity and Gravenberch's running: 0.25\n",
      "Premier League making changes to financial rules after Man City case: 0.25\n",
      "Replacing the irreplaceable - Pep's big Rodri conundrum: 0.25\n",
      "In defence of Fernandes: What's going wrong?: 0.24489795918367346\n",
      "Controversial Gordon penalty frustrates Man City: 0.24444444444444444\n",
      "'I can't believe what I'm watching!' | The tactic infuriating pundits: 0.24324324324324326\n",
      "Ten Hag: I'm not thinking about being sacked: 0.24242424242424243\n",
      "Why Villa boss Emery is much more than a great tactician: 0.24\n",
      "Using virtual reality to develop the next Haaland: 0.23880597014925373\n",
      "Man City's 115 charges: Hearing begins with Premier League: 0.23684210526315788\n",
      "'Coward' Haaland escapes punishment for throwing ball at Gabriel: 0.23529411764705882\n",
      "Evans: I admire Ten Hag's strength | 'Dressing room pushing for success': 0.23333333333333334\n",
      "Neville: Arsenal played like league winners | 'Perfect prep for City game': 0.23255813953488372\n",
      "Mourinho: Trust shown in Ten Hag differs to my Man Utd tenure: 0.23076923076923078\n",
      "Obi-Martin confirms Man Utd move after Arsenal exit: 0.23076923076923078\n",
      "Pep asks for clarity over Arteta's Man City 'dark arts' comments: 0.22916666666666666\n",
      "Saliba sees red as Bournemouth end Arsenal's unbeaten start: 0.22916666666666666\n",
      "Papers: Barca legend Xavi in frame if Man Utd axe Ten Hag: 0.22580645161290322\n",
      "Pep irked by Rodri questions and addresses Haaland 'knocks': 0.22580645161290322\n",
      "No Man Utd approach for Tuchel: 0.2222222222222222\n",
      "Solanke off the mark as Spurs defeat Brentford: 0.21739130434782608\n",
      "Man City's Rodri out for season; confirms Guardiola: 0.21568627450980393\n",
      "Late Mateta pen secures Crystal Palace draw against Leicester: 0.21052631578947367\n",
      "'I feel very inspired' - Arteta signs new Arsenal contract: 0.20588235294117646\n",
      "Why 'beautiful footballer' Dibling is Southampton's light in the dark: 0.20588235294117646\n",
      "Gibbs-White; Nuno and Hurzeler see red as Brighton and Forest draw: 0.20454545454545456\n",
      "Ten Hag explains shock Rashford sub in chaotic Porto draw: 0.2\n",
      "What The Friedkin Group may bring to Everton: 0.2\n",
      "Man City charges Q&A: What are the allegations? What are the punishments?: 0.1951219512195122\n",
      "The alarming English coaching stats as Tuchel gets England job: 0.19047619047619047\n",
      "Marcus Stewart: I don't live with MND; it lives with me: 0.1875\n",
      "Do clubs still need 40 points to survive in Premier League?: 0.18181818181818182\n",
      "Papers: Cole to leave Birmingham for full-time FA role: 0.18181818181818182\n",
      "QUIZ: Know the PL? Draw every club's all-time league positions: 0.18181818181818182\n",
      "Saka leaves England camp for further assessment on injury: 0.18181818181818182\n",
      "Dyche 'won't throw dummy out of pram' amid speculation over future: 0.17857142857142858\n",
      "Papers: Van Nistelrooy to be offered interim Man Utd job if Ten Hag sacked: 0.17391304347826086\n",
      "Postecoglou's 'free-flowing' football can threaten Arsenal: 0.17142857142857143\n",
      "Merino can add extra weapon for Arsenal : 0.17073170731707318\n",
      "Aston Villa European Cup winner Shaw dies aged 63: 0.16666666666666666\n",
      "Man Utd are PL's biggest underachievers this season: 0.16666666666666666\n",
      "Martin retains Southampton board backing despite winless run: 0.16666666666666666\n",
      "Seven-hour meeting then silence... the state of play for Ten Hag at Man Utd: 0.16666666666666666\n",
      "Sky Sports Fantasy Podcast: Tips from snooker's Neil Robertson: 0.16666666666666666\n",
      "What's gone so wrong for Glasner at Crystal Palace?: 0.16176470588235295\n",
      "Man Utd preparing for new contract talks with Mainoo and Diallo: 0.15384615384615385\n",
      "Newcastle chief exec Eales to step down after cancer diagnosis: 0.15384615384615385\n",
      "Ten Hag responds to Ronaldo: He is far away from Manchester: 0.14814814814814814\n",
      "Essential Football pod: Where now for England and Carsley?: 0.14285714285714285\n",
      "Everton agree takeover deal - late twist explained and what next?: 0.1388888888888889\n",
      "Arteta not ruling Odegaard out of NLD: 0.13636363636363635\n",
      "Does sacking a manager improve Premier League survival chances?: 0.13636363636363635\n",
      "Man Utd bosses back Ten Hag despite 'unacceptable' Spurs defeat: 0.13636363636363635\n",
      "Sir Alex stepping down from Man Utd role as INEOS cost-cutting continues: 0.1111111111111111\n",
      "Alisson to miss run of crunch Liverpool games: 0.06666666666666667\n",
      "Trent says trophies will be key when deciding Liverpool future: 0.06451612903225806\n",
      "Revealed: The Premier League's fastest players: 0.05263157894736842\n",
      "Brighton vs Wolves preview: Welbeck doubtful after injury at Newcastle: 0.0\n",
      "Crystal Palace 0-0 Man Utd highlights: 0.0\n",
      "Hojlund and Mount return to Man Utd training : 0.0\n",
      "Ipswich level in the 95th minute at Saints LIVE! : 0.0\n",
      "Leicester City vs Nottingham Forest live on Sky: Cooper faces former club: 0.0\n",
      "Liverpool vs Man City; Chelsea vs Arsenal live on Sky Sports: 0.0\n",
      "Martin delivers brutal Saints verdict - full transcript: 0.0\n",
      "Podcast: What we've learnt from the Premier League season so far: 0.0\n",
      "Ref Watch: 'FA will decide on retrospective Jackson punishment': 0.0\n"
     ]
    }
   ],
   "source": [
    "def print_argument_density(argument_density_per_topic):\n",
    "    sorted_density = sorted(argument_density_per_topic.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"Article Topic - Argument Density:\")\n",
    "    for topic, density in sorted_density:\n",
    "        print(f\"{topic}: {density}\")\n",
    "\n",
    "print_argument_density(argument_density_per_topic)\n",
    "\n",
    "\"\"\"\n",
    "Could be interesting to look into, however I don't know how to make it more useful now\n",
    "More opionated the article topic, higher the argument density\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# adjusting the vocab file\n",
    "import re\n",
    "\n",
    "unique_words = set()\n",
    "\n",
    "for sen in df['sentence']:\n",
    "    tokens = sen.split()\n",
    "    for token in tokens:\n",
    "        unique_words.add(token)\n",
    "\n",
    "with open(\"enhanced_vocab.txt\", 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "filtered_vocab_set = set(line.strip() for line in lines)\n",
    "\n",
    "with open(\"enhanced_vocab.txt\", 'a', encoding='utf-8') as f:\n",
    "    for word in unique_words:\n",
    "        filtered_word = re.sub(r\"[.,\\[\\]()\\\"':;?/!&^@\\\\]\", \"\", word.strip().lower())\n",
    "        if filtered_word not in filtered_vocab_set:\n",
    "            f.write(f\"{filtered_word}\\n\") \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't think I can use a pre-trained model with a custom pre-trained tokenizer because not all the tokens the model is trained with will be present in the new vocabulary of the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['argument_density', 'article_topic'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>best</th>\n",
       "      <th>better</th>\n",
       "      <th>big</th>\n",
       "      <th>did</th>\n",
       "      <th>going</th>\n",
       "      <th>good</th>\n",
       "      <th>just</th>\n",
       "      <th>know</th>\n",
       "      <th>...</th>\n",
       "      <th>win</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADV</th>\n",
       "      <th>PRON</th>\n",
       "      <th>WDT</th>\n",
       "      <th>PREP</th>\n",
       "      <th>MODAL</th>\n",
       "      <th>NUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bukayo Saka has left the England training camp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Arsenal winger limped off during the secon...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bukayo would have been close but it would have...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He's a positive person and I expect him to be ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saka continues to be assessed by the Arsenal m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence label  best  better  big  \\\n",
       "0  Bukayo Saka has left the England training camp...     0   0.0     0.0  0.0   \n",
       "1  The Arsenal winger limped off during the secon...     0   0.0     0.0  0.0   \n",
       "2  Bukayo would have been close but it would have...     1   0.0     0.0  0.0   \n",
       "3  He's a positive person and I expect him to be ...     1   0.0     0.0  0.0   \n",
       "4  Saka continues to be assessed by the Arsenal m...     0   0.0     0.0  0.0   \n",
       "\n",
       "   did  going  good  just  know  ...  win      NOUN      VERB       ADJ  \\\n",
       "0  0.0    0.0   0.0   0.0   0.0  ...  0.0  0.375000  0.166667  0.041667   \n",
       "1  0.0    0.0   0.0   0.0   0.0  ...  0.0  0.406250  0.062500  0.031250   \n",
       "2  0.0    0.0   0.0   0.0   0.0  ...  0.0  0.095238  0.285714  0.047619   \n",
       "3  0.0    0.0   0.0   0.0   0.0  ...  0.0  0.076923  0.230769  0.153846   \n",
       "4  0.0    0.0   0.0   0.0   0.0  ...  0.0  0.300000  0.200000  0.050000   \n",
       "\n",
       "        ADV      PRON  WDT      PREP     MODAL  NUM  \n",
       "0  0.000000  0.041667  0.0  0.166667  0.000000  0.0  \n",
       "1  0.031250  0.000000  0.0  0.218750  0.031250  0.0  \n",
       "2  0.047619  0.142857  0.0  0.095238  0.095238  0.0  \n",
       "3  0.000000  0.230769  0.0  0.076923  0.000000  0.0  \n",
       "4  0.050000  0.000000  0.0  0.250000  0.000000  0.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('tokenized_data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
